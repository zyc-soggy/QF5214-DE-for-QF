{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:25:09.250804Z",
     "start_time": "2024-04-01T13:25:09.248836Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['3.27.226.3:9092'], #change ip here\n",
    "                         value_serializer=lambda x:\n",
    "                         dumps(x).encode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:23:35.532065Z",
     "start_time": "2024-04-01T12:23:35.071954Z"
    }
   },
   "id": "9b037239f391d839",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ProducerPlus(stock_code, start_page, end_page): # 初始化变量i\n",
    "    while True:\n",
    "        all_comments = []  # 初始化存储评论的列表\n",
    "        for page_num in range(start_page, end_page + 1):\n",
    "            url = f\"http://guba.eastmoney.com/list,{stock_code},f_{page_num}.html\"\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers)\n",
    "    \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                comments = soup.find_all('tr', class_='listitem')  # 获取所有评论项\n",
    "                for comment in comments:\n",
    "                    # 提取所需字段\n",
    "                    read = comment.find('div', class_='read').text if comment.find('div', class_='read') else 'N/A'\n",
    "                    reply = comment.find('div', class_='reply').text if comment.find('div', class_='reply') else 'N/A'\n",
    "                    title_div = comment.find('div', class_='title')\n",
    "                    title = title_div.get_text(strip=True) if title_div else 'N/A'\n",
    "                    author = comment.find('div', class_='author').text if comment.find('div', class_='author') else 'N/A'\n",
    "                    update_time = comment.find('div', class_='update').text if comment.find('div',\n",
    "                                                                                            class_='update') else 'N/A'\n",
    "    \n",
    "                    # 收集数据\n",
    "                    all_comments.append({\n",
    "                        \"页码\": page_num,\n",
    "                        \"阅读\": read,\n",
    "                        \"回复\": reply,\n",
    "                        \"标题\": title,\n",
    "                        \"作者\": author,\n",
    "                        \"更新时间\": update_time\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"请求失败，状态码：{response.status_code}\")\n",
    "    # 将数据转换为DataFrame\n",
    "        df = pd.DataFrame(all_comments)\n",
    "        # 数据处理完成后，进行文件保存和差异计算等操作\n",
    "        fileNameNew = f\"comments_{stock_code}New.csv\"\n",
    "        fileNameOld = f\"comments_{stock_code}Old.csv\"\n",
    "        df.to_csv(fileNameNew, index=False, encoding='utf_8_sig')\n",
    "        print(f\"数据已保存到CSV文件：{fileNameNew}\")\n",
    "        if not os.path.isfile(fileNameOld):\n",
    "            print('creating old file')\n",
    "            with open(fileNameOld, \"w\") as fold:\n",
    "                fold.write(\"页码,阅读,回复,标题,作者,更新时间\")\n",
    "        # 计算New和Old文件的差异\n",
    "        df_old=pd.read_csv(fileNameOld)\n",
    "        difference = pd.merge(df, df_old, on='标题', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "        dict_difference = difference.to_dict(orient='records')\n",
    "        print(difference)\n",
    "        for row_dict in fileNameNew:\n",
    "            producer.send('Stock', value=dict_difference)\n",
    "            sleep(1)\n",
    "        shutil.copyfile(fileNameNew, fileNameOld)\n",
    "        print('moving new file to old file')\n",
    "        sleep(100)\n",
    "  # 使用os.replace代替os.system和mv命令"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:42:06.092060Z",
     "start_time": "2024-04-01T12:42:06.091578Z"
    }
   },
   "id": "1481cd1aec914f6c",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到CSV文件：comments_300750New.csv\n",
      "   页码_x 阅读_x 回复_x                             标题          作者_x       更新时间_x  \\\n",
      "4     1    6    0                         牛，还有翻倍          百股花香  04-01 08:38   \n",
      "5     1    5    0                        宁德时代能好吗  股友2l6737337a  04-01 08:38   \n",
      "6     1   29    0  2024.4.1A股分析（应更注意操作品种自身技术面信息）         白白胖胖0  04-01 08:37   \n",
      "7     1   39    0                   满仓满融杀入，坐等起飞！         带散户斗庄  04-01 08:26   \n",
      "\n",
      "   页码_y  阅读_y  回复_y 作者_y 更新时间_y  \n",
      "4   NaN   NaN   NaN  NaN    NaN  \n",
      "5   NaN   NaN   NaN  NaN    NaN  \n",
      "6   NaN   NaN   NaN  NaN    NaN  \n",
      "7   NaN   NaN   NaN  NaN    NaN  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mProducerPlus\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m300750\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[28], line 51\u001B[0m, in \u001B[0;36mProducerPlus\u001B[0;34m(stock_code, start_page, end_page)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_dict \u001B[38;5;129;01min\u001B[39;00m fileNameNew:\n\u001B[1;32m     50\u001B[0m     producer\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStock\u001B[39m\u001B[38;5;124m'\u001B[39m, value\u001B[38;5;241m=\u001B[39mdict_difference)\n\u001B[0;32m---> 51\u001B[0m     \u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m shutil\u001B[38;5;241m.\u001B[39mcopyfile(fileNameNew, fileNameOld)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmoving new file to old file\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ProducerPlus('300750', 1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:42:30.005036Z",
     "start_time": "2024-04-01T12:42:08.188284Z"
    }
   },
   "id": "fdd88f390f628515",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "producer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:40:31.910491Z",
     "start_time": "2024-04-01T12:40:31.907971Z"
    }
   },
   "id": "eda36110aba0e92a",
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
